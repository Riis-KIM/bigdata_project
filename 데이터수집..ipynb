{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Term_project_test(10~15).ipynb","provenance":[{"file_id":"1GgRnKEGOz5weexfg1OUCJ_T5mW9riYSm","timestamp":1593870512883}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"6PnN-VyYRlXV","colab_type":"code","colab":{}},"source":["!pip install bs4 requests pandas\n","\n","import pandas as pd\n","import requests\n","from bs4 import BeautifulSoup"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nA7flSxhSEUa","colab_type":"code","colab":{}},"source":["multi_page_result = list()\n","\n","for i in range(0, 15):\n","  url = \"https://www.metacritic.com/browse/games/score/metascore/all/all/filtered?page=\" + str(i)\n","  headers = {'User-Agent':'Chrome/66.0.3359.181'}\n","  html = requests.get(url,headers=headers) ##requests 를 이용해서 url의 html 파일을 가져옴\n","  soup = BeautifulSoup(html.text, \"html.parser\") ##가져온 html 파일을 html parser를 통해서 정리\n","\n","  platform_list = list()\n","  html_platform_list = soup.findAll(\"div\", attrs={\"class\":\"platform\"})\n","  first = 0\n","  for line in html_platform_list:\n","    text = line.get_text()\n","    platform_list.append(text)\n","  \n","  preprocess_platform = list()\n","  for platform_text in platform_list:\n","    platform_text = platform_text.replace(\"\\n\", \"\")\n","    platform_text = platform_text.replace(\"Platform:\", \"\")\n","    platform_text = platform_text.replace(\"All Platforms\",\"\")\n","    platform_text = platform_text.strip()\n","    platform_text = platform_text.replace(\" \", \"-\").strip() #공백을 -로 변환\n","    platform_text = platform_text.lower()\n","    if(first == 0):\n","      first = first+1\n","    else:\n","      preprocess_platform.append(platform_text)\n","\n","  detail = list()\n","  detail = soup.findAll(\"a\", attrs={\"class\":\"title\"})\n","  name = list()\n","  for i in range(0,100): #게임 개수만큼\n","    for line in detail[i]:\n","     text = line.get_text()\n","     text = text.replace(\" &\", \"\")\n","     text = text.replace(\":\", \"\")          # : 를 없앰\n","     text = text.replace(\";\", \"\")\n","     text = text.lower()\n","     text = text.replace(\"'\", \"\")\n","     text = text.replace(\".\", \"\")\n","     text = text.replace(\",\", \"\")\n","     text = text.replace(\"#\", \"\")\n","     text = text.replace(\"$!\", \"!\")\n","     text = text.replace(\" /\", \"\")\n","     text = text.replace(\" \", \"-\").strip() #공백을 -로 변환\n","     name.append(text)\n","  \n","  preprocess_date = list() \n","  preprocess_genre = list()\n","  preprocess_userscore = list()\n","  preprocess_metascore = list()\n","  new_genre = list()  \n","  \n","  for j in range(0,100): \n","    url2_1 = \"https://www.metacritic.com/game/\"\n","    url2_2 = preprocess_platform[j]+\"/\"\n","    url2_3 = name[j]\n","    url2 = url2_1 + url2_2 + url2_3\n","  \n","    headers2 = {'User-Agent':'Chrome/66.0.3359.181'}\n","    html2 = requests.get(url2,headers=headers2)\n","    soup2 = BeautifulSoup(html2.text, 'html.parser')\n","\n","    date_detail = list()\n","    date = list()\n","    genre_detail = list()\n","    genre = list()\n","\n","    date_detail = soup2.findAll(\"li\", attrs={\"class\":\"summary_detail release_data\"})\n","    print(date_detail)\n","    print(name[j])\n","    date = date_detail[0].find_all('span',{'class':'data'})\n","    for art in date:\n","      art = art.text.strip()\n","      preprocess_date.append(art)\n","\n","    usescore = list()\n","    pu_score = list()\n","    mu_score = list()\n","    nu_score = list()\n","    pm_score = list()\n","    mm_score = list()\n","    nm_score = list()\n","    usescore = soup2.findAll(\"a\", attrs={\"class\":\"metascore_anchor\"})\n","    pu_score = usescore[1].findAll(\"div\", attrs={\"class\":\"metascore_w user large game positive\"})\n","    mu_score = usescore[1].findAll(\"div\", attrs={\"class\":\"metascore_w user large game mixed\"})\n","    nu_score = usescore[1].findAll(\"div\", attrs={\"class\":\"metascore_w user large game negative\"})\n","    tu_score = usescore[1].findAll(\"div\", attrs={\"class\":\"metascore_w user large game tbd\"})\n","    pm_score = usescore[0].findAll(\"div\", attrs={\"class\":\"metascore_w xlarge game positive\"})\n","    mm_score = usescore[0].findAll(\"div\", attrs={\"class\":\"metascore_w xlarge game mixed\"})\n","    nm_score = usescore[0].findAll(\"div\", attrs={\"class\":\"metascore_w xlarge game negative\"})\n","    for art in pu_score:\n","      art = art.text.strip()\n","      preprocess_userscore.append(art)\n","    for art in mu_score:\n","      art = art.text.strip()\n","      preprocess_userscore.append(art)\n","    for art in nu_score:\n","      art = art.text.strip()\n","      preprocess_userscore.append(art)\n","    for art in tu_score:\n","      art = art.text.strip()\n","      preprocess_userscore.append(art)\n","    for art in pm_score:\n","      art = art.text.strip()\n","      preprocess_metascore.append(art)\n","    for art in mm_score:\n","      art = art.text.strip()\n","      preprocess_metascore.append(art)\n","    for art in nm_score:\n","      art = art.text.strip()\n","      preprocess_metascore.append(art)\n","\n","    html_label_list = soup.findAll(\"div\",attrs = {\"metascore_w\"})\n","    label_list = list()\n","\n","  for line in html_label_list:\n","    if(line.attrs[\"class\"][1] == 'user'):\n","      label = line.attrs[\"class\"][4]\n","    else:\n","      label = line.attrs[\"class\"][3]\n","    label_list.append(label)\n","  \n","  result_list = list()\n","  for label, platform, name, date, metascore, userscore in zip(label_list, preprocess_platform,\n","                                                               name, preprocess_date, \n","                                                               preprocess_metascore, preprocess_userscore):\n","    row_data = [label, platform, name, date, metascore, userscore]\n","    multi_page_result.append(row_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o-FvyG6CTHXj","colab_type":"code","colab":{}},"source":["import pandas as pd\n","\n","review_df = pd.DataFrame(multi_page_result, columns =['label', 'platform', 'name','date', 'metascore', 'userscore'])\n","review_df\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jUMc80AV_XM-","colab_type":"code","colab":{}},"source":["review_df.to_excel('review10~15.xlsx')"],"execution_count":null,"outputs":[]}]}